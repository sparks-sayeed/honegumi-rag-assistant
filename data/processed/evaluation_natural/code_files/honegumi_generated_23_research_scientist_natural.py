# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"


def branin(x1, x2):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    return y


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
    },
)


for i in range(19):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    results = branin(x1, x2)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

best_parameters, metrics = ax_client.get_best_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
ax.scatter(df.index, df[objectives], ec="k", fc="none", label="Observed")
ax.plot(
    df.index,
    np.minimum.accumulate(df[objectives]),
    color="#0033FF",
    lw=2,
    label="Best to Trial",
)
ax.set_xlabel("Trial Number")
ax.set_ylabel(objectives[0])

ax.legend()
plt.show()

# Neural network hyperparameter optimization with Ax (40-trial budget)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ax.service.ax_client import AxClient, ObjectiveProperties


objective_name = "validation_accuracy"


def evaluate_training_configuration(
    learning_rate: float,
    weight_decay: float,
    dropout_rate: float,
    trial_index: int,
) -> dict:
    """Return simulated validation accuracy for a neural network training configuration.

    This function is a realistic stub to make this script executable without heavy ML frameworks.
    Replace the body with actual training and evaluation logic for your model.

    Example real implementation outline:
    - Set random seeds for reproducibility
    - Initialize your model (e.g., PyTorch or TensorFlow)
    - Configure optimizer with learning_rate and weight_decay
    - Apply dropout_rate in the model architecture
    - Train on your training split, evaluate on validation split
    - Return the measured validation accuracy in [0, 1]

    The simulation below creates a smooth landscape with noise to emulate training stochasticity.
    """
    rng = np.random.default_rng(seed=trial_index + 12345)

    # "True" sweet spots for this synthetic landscape
    lr_opt = 1e-3
    wd_opt = 1e-4
    dr_opt = 0.15

    # Convert to log10 for LR and WD since these are typically log-scaled
    log_lr = np.log10(learning_rate)
    log_lr_opt = np.log10(lr_opt)
    log_wd = np.log10(weight_decay)
    log_wd_opt = np.log10(wd_opt)

    # Gaussian-like responsiveness around optima
    lr_term = np.exp(-0.5 * ((log_lr - log_lr_opt) / 0.5) ** 2)
    wd_term = np.exp(-0.5 * ((log_wd - log_wd_opt) / 0.75) ** 2)
    dr_term = np.exp(-0.5 * ((dropout_rate - dr_opt) / 0.2) ** 2)

    # Interaction: slightly higher LR can benefit from moderate dropout
    interaction = 0.05 * np.exp(-0.5 * ((log_lr - np.log10(3e-3)) / 0.4) ** 2) * np.exp(
        -0.5 * ((dropout_rate - 0.25) / 0.15) ** 2
    )

    # Penalty for excessive dropout
    penalty = 0.05 * max(dropout_rate - 0.5, 0.0) ** 2

    # Compose score and add noise to emulate stochastic training
    base = 0.50 + 0.25 * lr_term + 0.15 * wd_term + 0.10 * dr_term + interaction - penalty
    noise = rng.normal(loc=0.0, scale=0.01)
    score = float(np.clip(base + noise, 0.0, 1.0))

    return {objective_name: score}


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {
            "name": "learning_rate",
            "type": "range",
            "bounds": [1e-5, 1e-1],
            "log_scale": True,
        },
        {
            "name": "weight_decay",
            "type": "range",
            "bounds": [1e-6, 1e-2],
            "log_scale": True,
        },
        {
            "name": "dropout_rate",
            "type": "range",
            "bounds": [0.0, 0.6],
        },
    ],
    objectives={
        objective_name: ObjectiveProperties(minimize=False),
    },
)

# 40-model budget
for _ in range(40):
    parameterization, trial_index = ax_client.get_next_trial()

    # Extract hyperparameters
    learning_rate = parameterization["learning_rate"]
    weight_decay = parameterization["weight_decay"]
    dropout_rate = parameterization["dropout_rate"]

    # Evaluate configuration
    try:
        results = evaluate_training_configuration(
            learning_rate=learning_rate,
            weight_decay=weight_decay,
            dropout_rate=dropout_rate,
            trial_index=trial_index,
        )
    except Exception as e:
        # Mark trial as failed if evaluation crashes
        ax_client.log_trial_failure(trial_index=trial_index)
        print(f"Trial {trial_index} failed with error: {e}")
        continue

    # Report results back to Ax
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

best_parameters, best_metrics = ax_client.get_best_parameters()

# Print best-found configuration and metric
best_val = best_metrics[objective_name]["mean"]
best_sem = best_metrics[objective_name].get("sem", None)
print("Best hyperparameters found:")
for k, v in best_parameters.items():
    print(f"  {k}: {v}")
print(f"Best {objective_name}: {best_val:.4f}" + (f" Â± {best_sem:.4f}" if best_sem is not None else ""))

# Plot results
df = ax_client.get_trials_data_frame()
if "trial_index" in df.columns:
    df = df.sort_values("trial_index")
    x_vals = df["trial_index"].to_numpy()
else:
    df = df.sort_index()
    x_vals = df.index.to_numpy()

y_vals = df[objective_name].to_numpy()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
ax.scatter(x_vals, y_vals, ec="k", fc="none", label="Observed")
ax.plot(x_vals, np.maximum.accumulate(y_vals), color="#0033FF", lw=2, label="Best to Trial")
ax.set_xlabel("Trial Number")
ax.set_ylabel(objective_name)
ax.set_title("Neural Network Hyperparameter Optimization (Ax)")
ax.legend()
plt.tight_layout()
plt.show()