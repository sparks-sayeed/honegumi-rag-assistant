# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"


def branin(x1, x2):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    return y


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
    },
)


for i in range(19):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    results = branin(x1, x2)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

best_parameters, metrics = ax_client.get_best_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
ax.scatter(df.index, df[objectives], ec="k", fc="none", label="Observed")
ax.plot(
    df.index,
    np.minimum.accumulate(df[objectives]),
    color="#0033FF",
    lw=2,
    label="Best to Trial",
)
ax.set_xlabel("Trial Number")
ax.set_ylabel(objectives[0])

ax.legend()
plt.show()

# Generated comparison of BO strategies on Branin using Ax Platform
# %pip install ax-platform==0.4.3 matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch

from typing import Dict, List, Tuple

from ax.service.ax_client import AxClient, ObjectiveProperties
from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy
from ax.modelbridge.registry import Models

# BoTorch acquisition functions
from botorch.acquisition import qExpectedImprovement, qProbabilityOfImprovement, qUpperConfidenceBound


# Objective (deterministic Branin benchmark)
OBJECTIVE_NAME = "branin_value"

# Branin function over the canonical domain:
# branin_x1 in [-5, 10], branin_x2 in [0, 15]
def branin_function(branin_x1: float, branin_x2: float) -> float:
    x = float(branin_x1)
    y = float(branin_x2)
    a = 1.0
    b = 5.1 / (4.0 * np.pi**2)
    c = 5.0 / np.pi
    r = 6.0
    s = 10.0
    t = 1.0 / (8.0 * np.pi)
    return (a * (y - b * x**2 + c * x - r) ** 2) + s * (1 - t) * np.cos(x) + s


def build_generation_strategy(
    n_sobol: int,
    sobol_seed: int,
    botorch_acqf_class,
    acquisition_options: Dict = None,
) -> GenerationStrategy:
    """
    Build a two-step generation strategy:
    - Sobol initialization (n_sobol trials)
    - GP-based BO with specified acquisition function
    """
    acquisition_options = acquisition_options or {}
    gs = GenerationStrategy(
        steps=[
            GenerationStep(
                model=Models.SOBOL,
                num_trials=n_sobol,
                min_trials_observed=max(1, n_sobol // 2),
                max_parallelism=None,
                model_kwargs={"seed": sobol_seed},
            ),
            GenerationStep(
                model=Models.BOTORCH_MODULAR,
                num_trials=-1,
                max_parallelism=None,
                model_kwargs={
                    "botorch_acqf_class": botorch_acqf_class,
                    "acquisition_options": acquisition_options,
                },
            ),
        ]
    )
    return gs


def run_single_benchmark(
    acqf_name: str,
    botorch_acqf_class,
    acquisition_options: Dict,
    n_sobol: int,
    n_bayes: int,
    seed: int,
) -> pd.DataFrame:
    """
    Run one Ax optimization using a single acquisition function and random seed.
    Returns a DataFrame with per-iteration results.
    """
    # Ensure reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    gs = build_generation_strategy(
        n_sobol=n_sobol,
        sobol_seed=seed,
        botorch_acqf_class=botorch_acqf_class,
        acquisition_options=acquisition_options,
    )
    ax_client = AxClient(generation_strategy=gs)

    ax_client.create_experiment(
        name=f"branin_{acqf_name}_seed{seed}",
        parameters=[
            {"name": "branin_x1", "type": "range", "bounds": [-5.0, 10.0], "value_type": "float"},
            {"name": "branin_x2", "type": "range", "bounds": [0.0, 15.0], "value_type": "float"},
        ],
        objectives={OBJECTIVE_NAME: ObjectiveProperties(minimize=True)},
        overwrite_existing_experiment=True,
    )

    n_total = n_sobol + n_bayes
    observations: List[float] = []
    best_so_far: List[float] = []
    xs1: List[float] = []
    xs2: List[float] = []

    for it in range(n_total):
        params, trial_index = ax_client.get_next_trial()
        x1 = float(params["branin_x1"])
        x2 = float(params["branin_x2"])
        y = branin_function(x1, x2)

        ax_client.complete_trial(trial_index=trial_index, raw_data=y)

        observations.append(y)
        current_best = np.min(observations)
        best_so_far.append(current_best)
        xs1.append(x1)
        xs2.append(x2)

    df = pd.DataFrame(
        {
            "iteration": np.arange(n_total),
            "observed": observations,
            "best_so_far": best_so_far,
            "branin_x1": xs1,
            "branin_x2": xs2,
            "acqf": acqf_name,
            "seed": seed,
        }
    )
    return df


def main():
    # Benchmark configuration
    n_sobol = 5
    n_bayes = 25
    seeds = [0, 1, 2, 3, 4]

    # Acquisition functions to compare
    # For UCB, beta controls exploration; adjust as desired.
    acqf_specs: Dict[str, Tuple[object, Dict]] = {
        "qEI": (qExpectedImprovement, {}),
        "qPI": (qProbabilityOfImprovement, {}),
        "qUCB_beta0.2": (qUpperConfidenceBound, {"beta": 0.2}),
    }

    all_results: List[pd.DataFrame] = []
    for acqf_name, (acqf_class, acqf_opts) in acqf_specs.items():
        for seed in seeds:
            df_run = run_single_benchmark(
                acqf_name=acqf_name,
                botorch_acqf_class=acqf_class,
                acquisition_options=acqf_opts,
                n_sobol=n_sobol,
                n_bayes=n_bayes,
                seed=seed,
            )
            all_results.append(df_run)

    results = pd.concat(all_results, ignore_index=True)

    # Print final best for each acqf/seed
    summary = (
        results.groupby(["acqf", "seed"])
        .agg(final_best=("best_so_far", "last"))
        .reset_index()
        .sort_values(["acqf", "seed"])
    )
    print("Final best Branin values per acquisition function and seed:")
    print(summary.to_string(index=False))

    # Aggregate across seeds for plotting mean convergence
    agg = (
        results.groupby(["acqf", "iteration"])
        .agg(
            mean_best=("best_so_far", "mean"),
            q25=("best_so_far", lambda x: np.quantile(x, 0.25)),
            q75=("best_so_far", lambda x: np.quantile(x, 0.75)),
        )
        .reset_index()
    )

    # Plot convergence: mean best-so-far with 25-75 percentile band
    plt.figure(figsize=(7, 5), dpi=150)
    for acqf_name in acqf_specs.keys():
        a = agg[agg["acqf"] == acqf_name]
        plt.plot(a["iteration"], a["mean_best"], lw=2, label=acqf_name)
        plt.fill_between(a["iteration"], a["q25"], a["q75"], alpha=0.15)
    plt.axvline(n_sobol - 0.5, color="gray", ls="--", lw=1, label="End Sobol init")
    plt.xlabel("Trial number")
    plt.ylabel("Best Branin value so far (lower is better)")
    plt.title("BO convergence on Branin: acquisition functions comparison")
    plt.legend()
    plt.tight_layout()
    plt.show()

    # Optional: scatter of sampled points for one representative run per acqf
    # Select the lowest final best seed per acqf for visualization
    rep_seeds = (
        summary.sort_values("final_best")
        .groupby("acqf")
        .head(1)[["acqf", "seed"]]
        .set_index("acqf")["seed"]
        .to_dict()
    )

    fig, axes = plt.subplots(1, len(acqf_specs), figsize=(4 * len(acqf_specs), 4), dpi=150, sharex=True, sharey=True)
    if len(acqf_specs) == 1:
        axes = [axes]
    for ax, (acqf_name, _) in zip(axes, acqf_specs.items()):
        seed = rep_seeds[acqf_name]
        df_rep = results[(results["acqf"] == acqf_name) and (results["seed"] == seed)]
        # The above line with "and" won't work elementwise, use '&' with parentheses:
        df_rep = results[(results["acqf"] == acqf_name) & (results["seed"] == seed)]
        sc = ax.scatter(
            df_rep["branin_x1"],
            df_rep["branin_x2"],
            c=df_rep["observed"],
            cmap="viridis_r",
            edgecolor="k",
        )
        ax.set_title(f"{acqf_name} (seed={seed})")
        ax.set_xlabel("branin_x1")
        ax.set_ylabel("branin_x2")
        ax.grid(alpha=0.2)
    fig.colorbar(sc, ax=axes, label="Observed Branin value")
    plt.suptitle("Sampled points colored by Branin value (lower is better)")
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()


if __name__ == "__main__":
    main()