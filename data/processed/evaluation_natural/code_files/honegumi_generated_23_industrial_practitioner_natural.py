# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib torch
import math
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, Tuple, List

import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset

from ax.service.ax_client import AxClient, ObjectiveProperties


# =============================================================================
# Problem: Hyperparameter tuning for a neural network classifier
# Objective: Maximize validation accuracy by tuning learning_rate, batch_size, dropout
# Budget: 40 trials
# Noise model: True (we estimate sem by repeating training with different seeds)
# =============================================================================

METRIC_NAME = "accuracy"

# -----------------------------------------------------------------------------
# Synthetic dataset generation (kept constant across trials)
# -----------------------------------------------------------------------------
def _sigmoid(z: np.ndarray) -> np.ndarray:
    return 1.0 / (1.0 + np.exp(-z))


def generate_synthetic_binary_classification(
    n_train: int = 1600,
    n_val: int = 400,
    n_features: int = 20,
    seed: int = 12345,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    rng = np.random.default_rng(seed)
    # Create a random linear decision boundary
    w = rng.normal(0.0, 1.0, size=(n_features,))
    b = rng.normal(0.0, 0.5)

    def sample_block(n: int) -> Tuple[np.ndarray, np.ndarray]:
        X = rng.normal(0.0, 1.0, size=(n, n_features))
        noise = rng.normal(0.0, 0.5, size=(n,))
        logits = X @ w + b + noise
        probs = _sigmoid(logits)
        y = (probs > 0.5).astype(np.int64)
        return X, y

    X_train, y_train = sample_block(n_train)
    X_val, y_val = sample_block(n_val)

    # Standardize features based on training set
    mean = X_train.mean(axis=0, keepdims=True)
    std = X_train.std(axis=0, keepdims=True) + 1e-8
    X_train = (X_train - mean) / std
    X_val = (X_val - mean) / std

    return X_train, y_train, X_val, y_val


X_TRAIN, Y_TRAIN, X_VAL, Y_VAL = generate_synthetic_binary_classification()
INPUT_DIM = X_TRAIN.shape[1]


# -----------------------------------------------------------------------------
# Model definition: Simple MLP with configurable dropout
# -----------------------------------------------------------------------------
class MLPClassifier(nn.Module):
    def __init__(self, input_dim: int, dropout_p: float):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Dropout(p=float(dropout_p)),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(p=float(dropout_p)),
            nn.Linear(32, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x).squeeze(-1)  # logits


def set_global_seeds(seed: int) -> None:
    np.random.seed(seed)
    torch.manual_seed(seed)


def train_and_evaluate_once(
    learning_rate: float,
    batch_size: int,
    dropout: float,
    seed: int,
    max_epochs: int = 5,
    device: str = "cpu",
) -> float:
    set_global_seeds(seed)

    model = MLPClassifier(INPUT_DIM, dropout_p=float(dropout)).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=float(learning_rate))
    criterion = nn.BCEWithLogitsLoss()

    # Clamp batch size to dataset size
    bs = max(1, min(int(batch_size), len(X_TRAIN)))

    # Build DataLoaders
    xtr = torch.from_numpy(X_TRAIN).float()
    ytr = torch.from_numpy(Y_TRAIN).float()
    xva = torch.from_numpy(X_VAL).float()
    yva = torch.from_numpy(Y_VAL).float()

    train_loader = DataLoader(TensorDataset(xtr, ytr), batch_size=bs, shuffle=True, drop_last=False)
    # Train
    model.train()
    for _ in range(max_epochs):
        for xb, yb in train_loader:
            xb = xb.to(device)
            yb = yb.to(device)
            optimizer.zero_grad(set_to_none=True)
            logits = model(xb)
            loss = criterion(logits, yb)
            loss.backward()
            optimizer.step()

    # Validate
    model.eval()
    with torch.no_grad():
        logits = model(xva.to(device))
        preds = (torch.sigmoid(logits) > 0.5).long().cpu().numpy()
    acc = (preds.flatten() == Y_VAL).mean().item()
    return float(acc)


def evaluate_model_accuracy(
    learning_rate: float,
    batch_size: int,
    dropout: float,
    n_repeats: int = 2,
    base_seed: int = 2024,
) -> Dict[str, Tuple[float, float]]:
    """
    Train the MLP multiple times with different seeds to estimate mean accuracy and SEM.
    Returns a dict: {METRIC_NAME: (mean, sem)}
    """
    # Ensure reasonable ranges
    learning_rate = float(np.clip(learning_rate, 1e-6, 1.0))
    batch_size = int(max(1, round(batch_size)))
    dropout = float(np.clip(dropout, 0.0, 0.95))

    accuracies: List[float] = []
    for r in range(n_repeats):
        seed = base_seed + r
        acc = train_and_evaluate_once(
            learning_rate=learning_rate, batch_size=batch_size, dropout=dropout, seed=seed
        )
        accuracies.append(acc)

    mean_acc = float(np.mean(accuracies))
    if n_repeats > 1:
        sem = float(np.std(accuracies, ddof=1) / math.sqrt(n_repeats))
    else:
        sem = 0.0

    return {METRIC_NAME: (mean_acc, sem)}


# -----------------------------------------------------------------------------
# Ax Optimization Setup
# -----------------------------------------------------------------------------
ax_client = AxClient()
ax_client.create_experiment(
    name="nn_hyperparameter_tuning_accuracy",
    parameters=[
        {
            "name": "learning_rate",
            "type": "range",
            "bounds": [1e-5, 1e-1],
            "log_scale": True,
        },
        {
            "name": "batch_size",
            "type": "range",
            "bounds": [16, 512],
            "value_type": "int",
            "log_scale": True,
        },
        {
            "name": "dropout",
            "type": "range",
            "bounds": [0.0, 0.7],
        },
    ],
    objectives={
        METRIC_NAME: ObjectiveProperties(minimize=False),
    },
)


# -----------------------------------------------------------------------------
# Optimization loop (Budget: 40 trials)
# -----------------------------------------------------------------------------
history_trials: List[int] = []
history_means: List[float] = []

TOTAL_TRIALS = 40
for _ in range(TOTAL_TRIALS):
    params, trial_index = ax_client.get_next_trial()

    # Extract hyperparameters
    lr = params["learning_rate"]
    bs = params["batch_size"]
    dr = params["dropout"]

    # Evaluate
    results = evaluate_model_accuracy(learning_rate=lr, batch_size=bs, dropout=dr, n_repeats=2)

    # Complete trial with metric dict: {metric_name: (mean, sem)}
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

    history_trials.append(trial_index)
    history_means.append(float(results[METRIC_NAME][0]))

best_parameters, best_values = ax_client.get_best_parameters()


# -----------------------------------------------------------------------------
# Report and Visualization
# -----------------------------------------------------------------------------
print("Best hyperparameters found:")
for k, v in best_parameters.items():
    print(f"  {k}: {v}")

best_mean = best_values[METRIC_NAME][0]
best_sem = best_values[METRIC_NAME][1]
print(f"Best observed {METRIC_NAME}: mean={best_mean:.4f}, sem={best_sem:.4f}")

# Plot observed accuracy and best-so-far
if history_means:
    trial_order = np.argsort(history_trials)
    trials_sorted = np.array(history_trials)[trial_order]
    acc_sorted = np.array(history_means)[trial_order]
    best_so_far = np.maximum.accumulate(acc_sorted)

    fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
    ax.scatter(trials_sorted, acc_sorted, ec="k", fc="none", label="Observed")
    ax.plot(trials_sorted, best_so_far, color="#0033FF", lw=2, label="Best so far")
    ax.set_xlabel("Trial Number")
    ax.set_ylabel("Validation Accuracy")
    ax.set_ylim(0.0, 1.0)
    ax.legend()
    plt.show()