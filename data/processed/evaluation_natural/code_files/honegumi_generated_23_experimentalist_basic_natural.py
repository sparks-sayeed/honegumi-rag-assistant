# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


# Problem: Tune neural network hyperparameters (learning rate, batch size, dropout)
# Objective: Maximize validation accuracy under a budget of 40 trials.
# Note: The evaluation below simulates training accuracy with realistic trends and noise.
# Replace `simulate_validation_accuracy` with actual training/evaluation for real use.


objective_name = "validation_accuracy"


def simulate_validation_accuracy(learning_rate: float, batch_size: int, dropout: float, rng: np.random.Generator) -> float:
    """
    Simulated validation accuracy for a neural network as a function of hyperparameters.
    Captures typical behaviors:
      - Learning rate has a "sweet spot" around ~3e-3 (too high or too low degrades).
      - Moderate dropout (~0.2-0.3) helps; too high hurts.
      - Batch size around 64-128 is often favorable.
      - Includes mild interaction effects and observation noise.
    Returns accuracy in [0.0, 1.0].
    """
    # Transformations for smooth scoring
    log10_lr = np.log10(learning_rate)
    lr_peak = np.log10(3e-3)
    lr_sigma = 0.75
    lr_score = np.exp(-((log10_lr - lr_peak) ** 2) / (2 * lr_sigma**2))

    drop_peak = 0.25
    drop_sigma = 0.18
    drop_score = np.exp(-((dropout - drop_peak) ** 2) / (2 * drop_sigma**2))

    log2_bs = np.log2(batch_size)
    bs_peak = 6.5  # ~ between 64 (2^6) and 128 (2^7)
    bs_sigma = 1.0
    bs_score = np.exp(-((log2_bs - bs_peak) ** 2) / (2 * bs_sigma**2))

    # Interaction and penalty terms
    high_lr_penalty = 0.04 if learning_rate > 5e-3 else 0.0
    heavy_drop_penalty = 0.03 if dropout > 0.5 else 0.0
    small_bs_penalty = 0.02 if batch_size < 32 else 0.0

    # Combine into a pseudo-accuracy
    base = 0.60
    acc = (
        base
        + 0.25 * lr_score
        + 0.10 * bs_score
        + 0.15 * drop_score
        + 0.05 * lr_score * drop_score
        + 0.03 * bs_score * drop_score
        - high_lr_penalty
        - heavy_drop_penalty
        - small_bs_penalty
    )

    # Add measurement noise to reflect stochastic training
    noise = rng.normal(loc=0.0, scale=0.01)
    acc = float(np.clip(acc + noise, 0.0, 1.0))
    return acc


# Ax client setup
ax_client = AxClient(random_seed=42)

ax_client.create_experiment(
    name="neural_net_hyperparameter_tuning",
    parameters=[
        {
            "name": "learning_rate",
            "type": "range",
            "bounds": [1e-5, 1e-1],
            "log_scale": True,
        },
        {
            "name": "batch_size",
            "type": "choice",
            "values": [16, 32, 64, 128, 256],
            "value_type": "int",
        },
        {
            "name": "dropout",
            "type": "range",
            "bounds": [0.0, 0.6],
            "value_type": "float",
        },
    ],
    objectives={
        objective_name: ObjectiveProperties(minimize=False),
    },
)

rng = np.random.default_rng(12345)

# Optimization loop with a budget of 40 trials
num_trials = 40
for _ in range(num_trials):
    parameterization, trial_index = ax_client.get_next_trial()

    # Extract parameters
    lr = float(parameterization["learning_rate"])
    bs = int(parameterization["batch_size"])
    dr = float(parameterization["dropout"])

    # Evaluate (replace this simulation with actual model training/evaluation)
    accuracy = simulate_validation_accuracy(lr, bs, dr, rng)

    # Report mean and SEM to Ax (SEM set to a small positive value to reflect noise)
    ax_client.complete_trial(
        trial_index=trial_index,
        raw_data={objective_name: (accuracy, 0.01)},
    )

best_parameters, metrics = ax_client.get_best_parameters()
best_acc_mean = metrics[objective_name][0]
best_acc_sem = metrics[objective_name][1]

print("Best hyperparameters found:")
print(best_parameters)
print(f"Estimated best {objective_name}: {best_acc_mean:.4f} Â± {best_acc_sem:.4f}")

# Plot results
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(7, 4), dpi=150)
ax.scatter(df.index, df[objective_name], ec="k", fc="none", label="Observed")
ax.plot(
    df.index,
    np.maximum.accumulate(df[objective_name]),
    color="#0033FF",
    lw=2,
    label="Best to Trial",
)
ax.set_xlabel("Trial Number")
ax.set_ylabel("Validation Accuracy")
ax.set_title("Bayesian Optimization of NN Hyperparameters (Accuracy)")
ax.set_ylim(0.5, 1.0)
ax.legend()
plt.tight_layout()
plt.show()