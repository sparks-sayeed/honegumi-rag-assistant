# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import math
import random
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ax.service.ax_client import AxClient, ObjectiveProperties
from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep
from ax.modelbridge.registry import Models


# -----------------------------
# Domain: Drug candidate selection with ADME optimization
# - Parameter: compound_id (categorical over up to 50 candidate compounds)
# - Objectives (maximize):
#     1) solubility (mg/mL)
#     2) permeability (cm/s)
#     3) binding_affinity (unitless, modeled here as pKd)
# - Budget: 50 trials
# - Noise: True (measurement noise present)
# -----------------------------

RANDOM_SEED = 123
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# Create a list of candidate compounds (IDs only; swap in your actual IDs/SMILES if available)
NUM_COMPOUNDS = 50
compound_ids: List[str] = [f"CMPD_{i:03d}" for i in range(1, NUM_COMPOUNDS + 1)]

# Synthesize a baseline property table for each compound to simulate realistic ADME trade-offs.
# This deterministic table represents "true" properties; the evaluation adds measurement noise.
def _generate_compound_property_table(ids: List[str]) -> Dict[str, Dict[str, float]]:
    properties: Dict[str, Dict[str, float]] = {}
    for cid in ids:
        # Latent physicochemical features (synthetic)
        logP = np.clip(np.random.normal(loc=2.5, scale=1.0), -1.0, 6.0)     # lipophilicity
        mw = np.clip(np.random.normal(loc=350.0, scale=80.0), 180.0, 650.0) # molecular weight (Da)
        psa = np.clip(np.random.normal(loc=75.0, scale=30.0), 10.0, 180.0)  # polar surface area (A^2)

        # Solubility (mg/mL): favor lower logP, lower MW, lower PSA
        # Model via log10 scale and exponentiate to mg/mL
        eps_s = np.random.normal(0.0, 0.2)
        log10_sol = 1.0 - 0.9 * logP - 0.004 * (mw - 300.0) - 0.008 * (psa - 75.0) + eps_s
        solubility = float(np.clip(10 ** log10_sol, 1e-3, 300.0))  # mg/mL

        # Permeability (cm/s): favor higher logP, lower PSA, slightly lower MW
        eps_p = np.random.normal(0.0, 0.25)
        log10_perm = -6.0 + 0.5 * logP - 0.003 * (psa - 60.0) - 0.001 * (mw - 300.0) + eps_p
        permeability = float(np.clip(10 ** log10_perm, 1e-7, 1e-4))  # cm/s

        # Binding affinity (pKd): favor higher logP, lower MW, lower PSA
        eps_b = np.random.normal(0.0, 0.2)
        binding_affinity = float(np.clip(7.0 + 0.3 * logP - 0.001 * (mw - 300.0) - 0.002 * (psa - 75.0) + eps_b, 5.0, 10.0))

        properties[cid] = {
            "solubility": solubility,
            "permeability": permeability,
            "binding_affinity": binding_affinity,  # pKd (higher is better)
        }
    return properties


compound_properties = _generate_compound_property_table(compound_ids)


def evaluate_adme_profile(compound_id: str) -> Dict[str, float]:
    """Evaluate ADME properties for a given compound.

    In a real use case, replace this with actual evaluation logic:
    - Run in vitro assays and record solubility (mg/mL) and permeability (cm/s)
    - Run binding assay against the target and compute pKd (or other affinity metric)
    - Fetch measurements from a LIMS / database
    """
    base = compound_properties[compound_id]

    # Add measurement noise to simulate experimental variability (heteroscedastic where appropriate)
    solubility_noise = np.random.normal(0.0, max(0.05 * base["solubility"], 0.01))
    permeability_noise = np.random.normal(0.0, max(0.15 * base["permeability"], 1e-8))
    binding_affinity_noise = np.random.normal(0.0, 0.1)

    solubility_val = max(0.0, base["solubility"] + solubility_noise)
    permeability_val = max(0.0, base["permeability"] + permeability_noise)
    binding_affinity_val = float(np.clip(base["binding_affinity"] + binding_affinity_noise, 0.0, None))

    return {
        "solubility": solubility_val,               # mg/mL
        "permeability": permeability_val,           # cm/s
        "binding_affinity": binding_affinity_val,   # pKd (dimensionless)
    }


# Configure a generation strategy suitable for multi-objective optimization on categorical space.
generation_strategy = GenerationStrategy(
    steps=[
        GenerationStep(
            model=Models.SOBOL,
            num_trials=min(12, NUM_COMPOUNDS // 2),  # modest initial exploration
            max_parallelism=12,
            model_kwargs={"deduplicate": True},
        ),
        GenerationStep(
            model=Models.MOO,  # qEHVI-based multi-objective BO (default GP)
            num_trials=-1,     # until budget exhausted
            max_parallelism=12,
        ),
    ]
)

ax_client = AxClient(generation_strategy=generation_strategy, enforce_sequential_optimization=False)

# Create the Ax experiment with the single categorical parameter and three objectives (all maximize).
ax_client.create_experiment(
    name="adme_multi_objective_optimization",
    parameters=[
        {
            "name": "compound_id",
            "type": "choice",
            "is_ordered": False,
            "values": compound_ids,
        }
    ],
    objectives={
        "solubility": ObjectiveProperties(minimize=False),         # mg/mL
        "permeability": ObjectiveProperties(minimize=False),       # cm/s
        "binding_affinity": ObjectiveProperties(minimize=False),   # pKd
    },
    overwrite_existing_experiment=True,
)

# Run optimization loop with the specified budget.
BUDGET = 50
for i in range(BUDGET):
    parameterization, trial_index = ax_client.get_next_trial()
    cid = parameterization["compound_id"]

    results = evaluate_adme_profile(cid)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# Retrieve Pareto-optimal results based on observed data only (no model predictions).
pareto_params = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)

# Prepare data frame of observed trials for visualization
trials_df = ax_client.get_trials_data_frame()

# Pivot to have one row per trial with columns for each metric's mean
metrics = ["solubility", "permeability", "binding_affinity"]
trial_metrics = trials_df.pivot(index="trial_index", columns="metric_name", values="mean").reset_index()

# Extract the compound_id per trial_index for labeling if needed
trial_params = trials_df[
    ["trial_index", "parameters.compound_id"]
].drop_duplicates(subset=["trial_index"])

obs_df = pd.merge(trial_metrics, trial_params, on="trial_index", how="left")

# Compute Pareto set (non-dominated) among observed trials for maximizing all objectives
def compute_pareto_mask(data: pd.DataFrame, objective_columns: List[str]) -> np.ndarray:
    vals = data[objective_columns].to_numpy()
    n = vals.shape[0]
    is_dominated = np.zeros(n, dtype=bool)
    for i in range(n):
        if is_dominated[i]:
            continue
        for j in range(n):
            if i == j:
                continue
            # j dominates i if j >= i for all objectives and strictly > for at least one
            if np.all(vals[j] >= vals[i]) and np.any(vals[j] > vals[i]):
                is_dominated[i] = True
                break
    return ~is_dominated

obs_df["is_pareto"] = compute_pareto_mask(obs_df, metrics)

# Visualization: pairwise scatter plots highlighting Pareto-optimal observations
pairs = [("solubility", "permeability"), ("solubility", "binding_affinity"), ("permeability", "binding_affinity")]
fig, axes = plt.subplots(1, 3, figsize=(15, 4), dpi=130)
for ax, (m1, m2) in zip(axes, pairs):
    ax.scatter(obs_df[m1], obs_df[m2], fc="None", ec="gray", label="Observed")
    pareto_points = obs_df[obs_df["is_pareto"]]
    ax.scatter(pareto_points[m1], pareto_points[m2], color="#0033FF", label="Pareto-optimal")
    ax.set_xlabel(m1)
    ax.set_ylabel(m2)
    ax.grid(True, alpha=0.3)
    ax.legend()

plt.tight_layout()
plt.show()

# Print a concise summary of Pareto-optimal compounds and their measured metrics
pareto_summary = obs_df[obs_df["is_pareto"]][["parameters.compound_id"] + metrics].sort_values(by=metrics, ascending=[False, False, False])
print("Pareto-optimal candidates (observed):")
print(pareto_summary.to_string(index=False))